[llm]
#model = "qwen3:14b"
#model = "huihui_ai/gpt-oss-abliterated:latest"
#model = "gpt4o"
#model = "llama3.1:70b-instruct-q4_K_M"
model = "llama3.1:8b"
api_key = "sk-local-dummy"
#base_url = "http://192.168.1.248:11434/api/chat"
base_url = "http://192.168.1.248:11434/v1/chat/completions"
max_tokens = 8192
#max_tokens = 4000
temperature = 0

[chunking]
chunk_size = 100  # Number of words per chunk
overlap = 20      # Number of words to overlap between chunks

[standardization]
enabled = true             # Whether to enable entity standardization
use_llm_for_entities = true  # Whether to use LLM for additional entity resolution

[inference]
enabled = true             # Whether to enable relationship inference
use_llm_for_inference = true  # Whether to use LLM for relationship inference
apply_transitive = true    # Whether to apply transitive inference rules

[visualization]
edge_smooth = false  # Options: false, "dynamic", "continuous", "discrete", "diagonalCross", 
                         # "straightCross", "horizontal", "vertical", "curvedCW", "curvedCCW", "cubicBezier": true = "continuous"
